<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Jintong Han Resume</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Jintong Han</strong> Homepage</a>
									<ul class="icons">
										<li><a href="https://www.linkedin.com/in/jintong-han-b328a0172/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
										<li><a href="https://github.com/hardy-jin" class="icon brands fa-github"><span class="label">Github</span></a></li>
										<li><a href="https://www.vanderbilt.edu/vise/visepeople/jintong-han/" class="icon far fa-id-card"><span class="label">VISE</span></a></li>
										<li><a href="https://www.youtube.com/channel/UCJhgMcf77tlEG9LDrt1Fpgw/featured" class="icon brands fa-youtube"><span class="label">Youtube</span></a></li>
									</ul>
								</header>

							<!-- Banner -->
								<section id="banner">
									<div id="id-homepage" class="content">
										<header>
											<h1>Jintong (Hardy) Han<br />
											</h1>
											<p>Welcome to my personal homepage</p>
										</header>
										<p>As an honor student, I have earned my bachelor's degree in computer science. I am a master's student in Computer Science at Vanderbilt University. I've developed an online education platform and evaluated it in some schools to enhance the user experience. I also developed an iOS application for social networking, focusing primarily on generating algorithmic recommendations and detecting objectionable comments and video content. I participated in extensive budget-conscious coding and decision-making. I was responsible for administering, installing, and utilizing computer and information technology. I worked at the Vanderbilt University Institute for Surgery and Engineering. Having a keen interest in applications of Computer Vision, machine learning, and data science, my current research focus is on Da Vinci surgical systems, Medical Image Processing, and Object Detection and Segmentation in a picture or video streams.</p>
										<ul class="actions">
											<li><a href="#" class="button big">RESUME</a></li>
										</ul>
									</div>
									<span class="image object">
										<img src="images/pic10.jpg" alt=""
										' />
									</span>
								</section>

							<!-- Section -->
								<section id="id-education">
									<header class="major">
										<h2>Education & Technical Skill</h2>
									</header>
									<div class="features">
										<article>
											<span class="icon fas fa-bell"></span>
											<div class="content">
												<h3>Master of Science</h3>
												<p>Vanderbilt University <br/> 
												Major: Computer Science	<br/>
											    Expected 2024. 05</p>
											</div>
										</article>
										<article>
											<span class="icon fas fa-edit"></span>
											<div class="content">
												<h3>Bachelor of Science</h3>
												<p>University of New Hampshire<br/>
												Major: Computer Science & Mathematics<br/>
												2017.08 - 2021. 05</p>
											</div>
										</article>
										<article>
											<span class="icon fas fa-file-code"></span>
											<div class="content">
												<h3>Programming Skill</h3>
												<p>Java, C/C++, Python, R, C#, Scala, Haskell, ROS, HTML, MongoDB, CSS, JavaScript</p>
											</div>
										</article>
										<article>
											<span class="icon fas fa-keyboard"></span>
											<div class="content">
												<h3>Technologies Skill</h3>
												<p>Linux, Postman, React, Angular, AWS, Redis, MySQL, RStudio, Git, Node.js, Anaconda, PyTorch, OpenCV, TensorFlow, Keras, Unity</p>
											</div>
										</article>
									</div>
								</section>

							<!-- Section -->
								<section id="id-work">
									<header class="major">
										<h2>Work Experience</h2>

									</header>
									<div class="posts">
										<article>
											<a class="image"><img src="images/rsz_vise-logo.jpg" alt="" /></a>
											<h3>Vanderbilt Institue for Surgery and Engineering</h3>
											<p>Trained a reinforcement learning policy for camera manipulation during Da Vinci robotic surgery. The
											application will not so much be for automation, as a scoring function for how well the surgeon has
											performed the camera manipulation by using several RL algorithms. <br/>
											Constructed a reinforcement learning pipeline where robot kinematics and endoscope images are input,
											and camera movement is the output.</p>
											<ul class="actions">
												<li><a href="https://www.vanderbilt.edu/vise/visepeople/jintong-han/" class="button">More</a></li>
											</ul>
										</article>
										<article>
											<a class="image"><img src="images/rsz_wechatimg711.jpg" alt="" /></a>
											<h3>Dual, LLC</h3>
											<p>Built, operated and maintained an automation Bot to detect inappropriate content, take action, and protect
												the community safely by using AWS AI service packages. Designed a tracking algorithm system to speed
												up the tool to handle real-time and learn from the past actions. <br />
												Analyzed and improved efficiency, accuracy, scalability, and stability of currently developed systems.</p>
											<ul class="actions">
												<li><a href="http://dual.monamedia.net/" class="button">More</a></li>
											</ul>
										</article>
										<article>
											<a class="image"><img src="images/rsz_wechatimg156.png" alt="" /></a>
											<h3>Tech Boom, LLC</h3>
											<p>Applied Vue/React/Angular framework to design the frontend and the API for several model functions.<br/>
											Used PostgreSQL setting up an online platform website and deployed on AWS. Used passport.js to
											complete the features of the user authentication. Redis was used as a buffer. Used SpringBoot
											/Node.js/Django framework, google Firebase, AWS personalize to implement some personalized
											recommendation algorithm for user and train and test amount of data. </p>
											<ul class="actions">
												<li><a href="https://www.techboom.online/" class="button">More</a></li>
											</ul>
										</article>
										<article>
											<a class="image"><img src="images/rsz_327d72c6e71ab1d15b2a775c6295a7a30.jpg" alt="" /></a>
											<h3>Yonghui Superstore</h3>
											<p>Used Axure and tools. Applied JAAS technologies to develop an interactive web page for users to register,
											login, search and apply. Developed three Java servlets with RESTful APIs to handle HTTP requests and
											responses. Built MySQL database on Amazon RDS to store position data fetched from Github API.<br/>
											Designed and created content-based algorithms using keywords extracted from MonkeyLearn API.
											Performed end-to-end tests of system functionality and deployed to Amazon EC2.</p>
											<ul class="actions">
												<li><a href="https://www.yonghui.com.cn/" class="button">More</a></li>
											</ul>
										</article>	
									</div>
								</section>

								<!-- Section -->
								<section id="id-research">
									<header class="major">
										<h2>Research Experience</h2>
								
									</header>
									<div class="posts">
										 <article>
											<a class="image"><img src="images/logo_miccai22.png" alt=""/></a>
											<h3>Endoscope Vision Challenge at MICCAI 2022 : Surgical Tool Localization in Endoscopic Videos</h3>
											<p>Completed and published a paper on the endoscope vision challenge of the MICCAI conference, especially in the surgical tool classification and localization area.
										 	Randomly selected the compelling video and cut the training video data of the da Vinci surgical robot by frame, removed invalid data, and trained the baseline model.
										 	Analyzed a simple transformer to do multi-label classification and then achieved weakly supervised object detection by extracting the attention maps from multi-head attention to localize the surgical tool.</p>
										</article>
										<article>
											<a class="image"><img src="images/Eyecod.png" alt="" /></a>
											<h3>Development of EyeCoD: Lensless FlatCam-based Eye-Tracking Algorithm and Accelerator Co-design Framework</h3>
											<p>Designed and implemented a customized accelerator co-design framework that seamlessly integrated the EyeCoD algorithm with MobileSAM.Conducted a comprehensive comparative analysis by evaluating the performance
											of EyeCoD. Compared the utilization of the vit-based image encoder and the entire pipeline with original SAM and MobileSAM, highlighting the superiority of the EyeCoD approach in terms of accuracy and computational efficiency.
											Implemented a process where eye images and pupil locations were utilized as prompts for the MobileSAM model. Implemented token merging based on the mask, ensuring precise feature extraction.</p>
										</article>
										<article>
											<a class="image"><img src="images/stego.png" alt=""/></a>
											<h3>Unsupervised Semantic Segmentation: Analysis and Optimization of the STEGO Framework</h3>
											<p>Using a contrastive loss, the STEGO unsupervised segmentation system learns by reducing picture correspondences into a set of class labels. Focus on learning a segmentation 
										 that takes into account the induced correspondences between items. To do this, a shallow segmentation network should be trained on top of the DINO ViT backbone using three contrastive
										 terms that extract connections between an image and itself, comparable images, and random other images, respectively. 
										 I reproduced the stego framework and study the optimization of its convolutional layers to optimize the algorithm based on this and create a new framework to improve the accuracy.</p>
										</article>
										<article>
											<a class="image"><img src="images/cmr-surgical-versius-clinical.webp" alt=""/></a>
											<h3>Reinforcement Learning for Camera Manipulation during Robotic Surgery</h3>
											<p>The application will not so much be for automation, as a scoring function for how well the surgeon has performed the
											camera manipulation. For every state, we would use the RL policy to determine what the score of the next camera state
											would be. And then we could sum up the scores of the actual path taken by the surgeon over the course of the operation
											and see what they get.</p>
										</article>
										<article>
											<a class="image"><img src="images/rsz_wx20220610-143941.png" alt="" /></a>
											<h3>Multimodal Brain Tumor Segmentation</h3>
											<p>I am working on this project which is to compare the performance between traditional itk-snap manual brain tumor segmentation with the state of art
											modified 3D Unet method.Manual medical image segmentation is a labor-intensive and time-consuming task with large inter-observer variability.The improved U-Net architecture has faster training speed and more accurate image segmentation than the baseline U-Net
											architecture and other existing efficient segmentation models.</p>
										</article>
										<article>
											<a class="image"><img src="images/rsz_11654988400897.jpg" alt="" /></a>
											<h3>Noncontact Anthropometry from IoT Camera in Smart City</h3>
											<p>The purpose of this article is to determine the dimensions of the human body from two-dimensional images taken from two
											distinct perspectives, using data from the IoT camera dataset. The BlazePose algorithm is used to extract 33 body part
											features from two views. The characteristics of the upper body are integrated with those of the height and body weight.
											After performing ensemble learning with the CatBoost algorithm, a regression prediction model is constructed. </p>
										</article>
										<article>
											<a class="image"><img src="images/rsz_wechatimg716.png" alt="" /></a>
											<h3>NASA Lunabot Robotic Mining</h3>
											<p>We should implement code to integrate sensors and motors including parsing sensor data to control LunaBot remotely.
											Implemented the code in the ROS Melodic environment to integrate sensors and motors including parsing sensor data to autonomous
											control Lunabot remotely. Used the RaspberryPI, the microcontroller, to parse data from the sensors,
											Lidar Lite and PixyCam, to construct roadmap and using shortest path algorithms in autopilot system. 
											Use SLAM algorithm to scan the map in the real-time.</p>
										</article>
									</div>
								</section>
								<!-- Section -->
								<section id="id-publication">
									<header class="major">
										<h2>Publications</h2>

									</header>
									<div class="posts">
										<article>
											<a class="image"><img src="images/framework1.png" alt="" /></a>
											<h3>Surgical tool classification and localization: results and methods from the MICCAI 2022 SurgToolLoc challenge</h3>
											<p>The ability to automatically detect and track surgical instruments in endoscopic videos can enable transformational interventions. 
												The ability to rely on tool installation data alone would significantly reduce the workload to train robust tool-tracking models.  
												The goal was to take full advantage of the auto-correlation and cross-correlation between various frame-to-frame and video-to-video 
												to solve this weakly supervised recognition problem. Therefore, an attention-base learning framework was selected to capture and detect causal features 
												that were directly related to surgical tool detection. </p>
											<ul class="actions">
												<li><a href="https://arxiv.org/abs/2305.07152" class="button">Paper</a></li>
											</ul>
										</article>
										<article>
											<a class="image"><img src="images/framework2.png" alt="" /></a>
											<h3>Self-supervised surgical instrument 3D reconstruction from a single camera image</h3>
											<p>In this paper, we first propose an end-to-end surgical instrument reconstruction system 
												-- Self-supervised Surgical Instrument Reconstruction (SSIR). With SSIR, we propose a multi-cycle-consistency strategy 
												to help capture the texture information from a slim instrument while only requiring a binary instrument label map. 
												Experiments demonstrate that our approach improves the reconstruction quality of surgical instruments compared to other 
												self-supervised methods and achieves promising results.</p>
											<ul class="actions">
												<li><a href="https://arxiv.org/abs/2211.14467" class="button">Paper</a></li>
											</ul>
										</article>
						
									</div>
								</section>

							
								<header class="major">
									<h2>Contact Me</h2>
								
								</header>
								<!-- modify this form HTML and place wherever you want your form -->
								<form action="https://formspree.io/f/xdobjwkp" method="POST">
									<div class="field half first">
										<label for="name">Full Name*</label>
										<input type="text" name="name" id="name" placeholder="Please type your full name.">
									</div>
									<label>
										Email*
										<input type="email" name="email">
									</label>
									<label>
										Type your message here...
										<textarea name="message"></textarea>
									</label>
									<!-- your other form fields go here -->
									<button type="submit">Send</button>
								</form>
						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section>

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="#id-homepage">Homepage</a></li>
										<li><a href="#id-education">Education & Technical Skill</a></li>
										<li><a href="#id-work">Work Experience</a></li>
										<li><a href="#id-research">Research Experience</a></li>
										<li><a href="#id-publication">Publications</a></li>
										<li>
											<span class="opener">Proof of Work</span>
											<ul>
												<li><a href="#">Resume</a></li>
												<li><a href="https://www.linkedin.com/in/jintong-han-b328a0172/">Linkedin</a></li>
												<li><a href="https://github.com/hardy-jin">Github</a></li>
												<li><a href="https://www.vanderbilt.edu/vise/visepeople/jintong-han/">VISE</a></li>
												<li><a href="https://www.youtube.com/channel/UCJhgMcf77tlEG9LDrt1Fpgw/featured">Youtube</a></li>
											</ul>
										</li>
									</ul>
								</nav>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Work Experience</h2>
									</header>
									<div class="mini-posts">
										<article>
											<a href="https://www.vanderbilt.edu/vise/visepeople/jintong-han/" class="image"><img src="images/rsz_vise-logo.jpg" alt="" /></a>
											<p>Vanderbilt Institue for Surgery and Engineering</p>
										</article>
										<article>
											<a href="http://dual.monamedia.net/" class="image"><img src="images/rsz_wechatimg711.jpg" alt="" /></a>
											<p>Dual, LLC</p>
										</article>
										<article>
											<a href="https://www.techboom.online/" class="image"><img src="images/rsz_wechatimg156.png" alt="" /></a>
											<p>Tech Boom, LLC</p>
										</article>
									
										<article>
											<a href="https://www.yonghui.com.cn/" class="image"><img src="images/rsz_327d72c6e71ab1d15b2a775c6295a7a30.jpg" alt="" /></a>
											<p>Yonghui Superstore</p>
										</article>
									</div>
									<ul class="actions">
										<li><a href="#" class="button">More</a></li>
									</ul>
								</section>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<p>Computer Science & Mathematics Student</p>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="#">hardyjin08@gmail.com</a></li>
										<li class="icon solid fa-phone">(603) 781-0397</li>
										<li class="icon solid fa-home">2801 Blakemore Ave<br />
										Nashville, TN 37212</li>
									</ul>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; 2022 by Jintong (Hardy) Han. All rights reserved.</p>
								</footer>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
